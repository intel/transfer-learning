metadata:
  name: medical-meadow
  namespace: kubeflow

secret:
  encodedToken:

image:
 name: amr-registry.caas.intel.com/aiops/mlops       # TODO: Replace with the public image/tag when it's available
 tag: torch-2.0.1-huggingface-multinode-python-3.9   # TODO: Replace with the public image/tag when it's available
 pullPolicy: IfNotPresent

elasticPolicy:
  rdzvBackend: c10d
  minReplicas: 1
  maxReplicas: 4  # Must be greater than or equal to the number of distributed.workers
  maxRestarts: 30

distributed:
  workers: 4
  script: /workspace/scripts/finetune.py
  modelNameOrPath: meta-llama/Llama-2-7b-hf
  logLevel: info

  doTrain: True
  doEval: True
  doBenchmark: False
  doQuantize: False

  train:
    datasetName: medalpaca/medical_meadow_medical_flashcards # Name of the Hugging Face dataset to use. Leave blank if using a data file
    dataFile: # Path to a dataset file. Leave blank if using a Hugging Face dataset.
    datasetConcatenation: True
    promptWithInput: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.
    promptWithoutInput: Below is an instruction that describes a task. Write a response that appropriately completes the request.
    perDeviceBatchSize: 8
    epochs: 3
    maxSteps: -1
    gradientAccumulationSteps: 1
    learningRate: 2e-5
    ddpFindUnusedParameters: False
    ddpBackend: ccl
    useFastTokenizer: False
    outputDir: /tmp/pvc-mount/output/saved_model
    loggingSteps: 10
    saveTotalLimit: 2
    saveStrategy: epoch
    useLora: True
    loraRank: 8
    loraAlpha: 16
    loraDropout: 0.1
    loraTargetModules: q_proj vproj
    noCuda: True
    overwriteOutputDir: True
    bf16: True
    useIpex: True
  eval:
    perDeviceBatchSize: 8
    validationSplitPercentage: 0.2
  benchmark:
    warmup: 30
    iterations: 300
    coresPerInstance: -1
    numInstances: 1
  quantize:
    peftModelDir: /tmp/pvc-mount/output/saved_model  # If training, set this to the train.outputDir to quantize the trained model
    outputDir: /tmp/pvc-mount/output/quantized_model
    woqBits: 8
    woqGroupSize: -1
    woqScheme: sym
    woqAlgo: RTN

envVars:
  ldPreload: /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4.5.9:/usr/local/lib/libiomp5.so
  logLevel: INFO
  transformersCache: /tmp/pvc-mount/transformers_cache
  hfDatasetsCache: /tmp/pvc-mount/hf_dataset_cache
  cclWorkerCount: 1
  httpProxy:
  httpsProxy:
  noProxy:
  ftpProxy:
  socksProxy:

# Resources allocated to each worker
resources:
  cpuRequest:
  cpuLimit:
  memoryRequest:
  memoryLimit:
  nodeSelectorLabel:
  nodeSelectorValue:

# Persistent volume claim storage resources
storage:
  storageClassName: nfs-client
  resources: 50Gi
  pvcMountPath: /tmp/pvc-mount
